package otmp


use core {package, string, array, iter, conv}
use core.alloc {as_allocator}

ParseError :: union {
    None: void;
    Unexpected_Token: TemplateToken;
    Expected_Token: TemplateToken.Type;

    Nested_Command: TemplateToken;

    Cannot_Nest_Blocks: TemplateToken;
}


#package
TemplateLexer :: struct {
    // The input string
    s: &str;
    line: u32;
    col:  u32;

    hit_eof := false;

    inside_command := false;
    inside_expression := false;
    error: ParseError;

    token_buffer: [..] TemplateToken;
}

TemplateToken :: struct {
    Type :: enum {
        Error;
        EOF;

        Text;   // Raw Text

        Command_Start; Command_End;
        Expression_Start; Expression_End;

        Keyword_Block;
        Keyword_EndBlock;
        Keyword_Foreach;
        Keyword_EndForeach;
        Keyword_In;
        Keyword_Extends;
        Keyword_Partial;

        String_Literal;
        Int_Literal;

        Variable;
        Symbol;

        Dot;
        Open_Bracket;
        Close_Bracket;
    }

    type: Type;
    text: str;
    line: u32;
    col:  u32;
}

#inject TemplateLexer {
    peek :: (self: &TemplateLexer, n := 0) -> TemplateToken {
        while n >= self.token_buffer.length {
            next := self->eat_next_token();
            if next.type == .EOF do return next;

            self.token_buffer << next;
        }

        return self.token_buffer[n];
    }

    consume :: (self: &TemplateLexer) -> TemplateToken {
        if !array.empty(self.token_buffer) {
            tkn := self.token_buffer[0];
            array.delete(&self.token_buffer, 0);
            return tkn;
        }

        tkn := self->eat_next_token();
        return tkn;
    }

    eat_characters :: (self: &TemplateLexer, chars := 1) -> str {
        for chars {
            if self.s.data[it] == #char "\n" {
                self.line += 1;
                self.col   = 0;
            }

            self.col += 1;
        }

        defer string.advance(self.s, chars);
        return self.s.data[0 .. chars];
    }

    eat_whitespace :: (self: &TemplateLexer) {
        while !string.empty(*self.s) {
            switch self.s.data[0] {
                case #char "\n", #char "\t", #char "\r", #char " " {
                    self->eat_characters(1);
                }

                case #default {
                    break break;
                }
            }
        }
    }

    eat_next_token :: (self: &TemplateLexer) -> TemplateToken {
        tkn: TemplateToken; 
        tkn.line = self.line;
        tkn.col  = self.col;
        
        self->eat_whitespace();

        if string.empty(*self.s) {
            self.hit_eof = true;
            yield_token(.EOF);
        }

        token_match("{{") {
            if self.inside_command {
                self.error = .{ Nested_Command = .{} };
                yield_token(.Error);
            }

            self.inside_command = true;
            yield_token(.Command_Start);
        }

        token_match("}}") {
            if self.inside_command {
                self.inside_command = false;
            }

            yield_token(.Command_End);
        }

        token_match("{%") {
            if self.inside_expression {
                self.error = .{ Nested_Command = .{} };
                yield_token(.Error);
            }

            self.inside_expression = true;
            yield_token(.Expression_Start);
        }

        token_match("%}") {
            if self.inside_expression {
                self.inside_expression = false;
            }

            yield_token(.Expression_End);
        }

        if self.inside_command || self.inside_expression {
            self->eat_whitespace();

            token_consume("block",      .Keyword_Block);            
            token_consume("endblock",   .Keyword_EndBlock);            
            token_consume("foreach",    .Keyword_Foreach);            
            token_consume("endforeach", .Keyword_EndForeach);            
            token_consume("in",         .Keyword_In);
            token_consume("extends",    .Keyword_Extends);
            token_consume("partial",    .Keyword_Partial);
            token_consume(".",          .Dot);
            token_consume("[",          .Open_Bracket);
            token_consume("]",          .Close_Bracket);

            if self.s.data[0] == #char "\"" {
                // :TODO add escaped strings
                self->eat_characters(1);

                index := string.index_of(*self.s, #char "\"");
                tkn.text = self->eat_characters(index);
                self->eat_characters(1);
                
                yield_token(.String_Literal);
            }

            if self.s.data[0] == #char "$" {
                self->eat_characters(1);

                chars := 0;
                while chars < self.s.length
                    && (self.s.data[chars]->is_alphanum() || self.s.data[chars] == '_')
                {
                     chars += 1;
                }

                tkn.text = self->eat_characters(chars);

                yield_token(.Variable);
            }

            if self.s.data[0]->is_num() {
                chars := 0;
                while chars < self.s.length && self.s.data[chars]->is_num() {
                     chars += 1;
                }

                tkn.text = self->eat_characters(chars);

                yield_token(.Int_Literal);
            }

            if self.s.data[0]->is_alphanum() {
                chars := 0;
                while chars < self.s.length &&
                    (self.s.data[chars]->is_alphanum() || self.s.data[chars] == #char "_") {
                     chars += 1;
                }

                tkn.text = self->eat_characters(chars);

                yield_token(.Symbol);
            }

        } else {
            length := 1;
            while self.s.data[length] != #char "{" && length < self.s.length {
                length += 1;
            }

            tkn.text = self->eat_characters(length);
            yield_token(.Text);
        }

        yield_token :: macro (kind: TemplateToken.Type) {
            tkn.type = kind;
            return tkn;
        }

        token_match :: macro (t: str, body: Code) {
            if string.starts_with(*self.s, t) {
                tkn.text = self->eat_characters(t.length);

                #unquote body;
            }
        }
        
        token_consume :: macro (t: str, kind: TemplateToken.Type) {
            if string.starts_with(*self.s, t) {
                tkn.text = self->eat_characters(t.length);
                yield_token(kind);
            }
        }
    }
}

#overload
delete :: (tl: &TemplateLexer) {
    delete(&tl.token_buffer);
}

#overload
iter.as_iter :: (tl: &TemplateLexer) => {
    return iter.generator(
        &.{ tl = tl, hit_error = false },
        
        (ctx) => {
            if !ctx.hit_error {
                tkn := ctx.tl->consume();
                if tkn.type == .Error || tkn.type == .EOF {
                    ctx.hit_error = true;
                }

                return tkn, true;
            }

            return .{}, false;
        }
    );
}


#package
TemplateParser :: struct {
    t: &Template;
    l: &TemplateLexer;

    instruction_targets: [..] &[..] &TNode;
}

#package
parse_template :: (t: &Template, s: &str) -> ParseError {
    l := TemplateLexer.{s};
    p := TemplateParser.{t, &l};
    p.instruction_targets << &t.instructions;
    defer delete(&p.instruction_targets);

    return parse_statements(&p);
}

#local
parse_statements :: (use p: &TemplateParser) -> ParseError {
    while !p.l.hit_eof {
        switch tkn := p.l->consume(); tkn.type {
            case .Command_Start {
                if err := parse_statement(p); err.tag != .None {
                    return err;
                }

                expect_token(p, .Command_End);
            }

            case .Expression_Start {
                if node, err := parse_expression(p); err.tag != .None {
                    return err;
                } else {
                    *array.get(instruction_targets, -1) << node;
                }

                expect_token(p, .Expression_End);
            }

            case .Text {
                text_node := make_node(t, .{
                    Text = string.alloc_copy(tkn.text, as_allocator(&t.node_storage))
                });
                *array.get(instruction_targets, -1) << text_node;
            }
        }
    }

    return .{ None = .{} };
}

#local
parse_statement :: (use p: &TemplateParser) -> ParseError {
    switch tkn := p.l->consume(); tkn.type {
        case .Keyword_Extends {
            text, err := parse_string(p);
            if err.tag != .None do return err;

            extend_node := make_node(t, TNode.{
                Extend = text
            });

            *array.get(instruction_targets, -1) << extend_node;
        }

        case .Keyword_Block {
            text, err := parse_string(p);
            if err.tag != .None do return err;

            block_node := make_node(t, .{
                Block = .{ block_name = text }
            });

            *array.get(instruction_targets, -1) << block_node;

            instruction_targets << &union_as_ptr(block_node, .Block).contents;
        }

        case .Keyword_EndBlock {
            array.pop(&instruction_targets);
        }

        case .Keyword_Foreach {
            var_tkn: TemplateToken;
            expect_token(p, .Variable, #(var_tkn));

            expect_token(p, .Keyword_In);

            iter_tkn: TemplateToken;
            expect_token(p, .Variable, #(iter_tkn));

            var_expr := do {
                name := string.alloc_copy(iter_tkn.text, as_allocator(&t.node_storage));

                var_expr := make_node(t, .{ ExprVar = .{ var_name = name } });
                return var_expr;
            };

            for_node := make_node(t, .{
                Foreach = .{
                    var_name = string.alloc_copy(var_tkn.text, as_allocator(&t.node_storage)),
                    list = var_expr,
                }
            });

            *array.get(instruction_targets, -1) << for_node;
            instruction_targets << &union_as_ptr(for_node, .Foreach).body;
        }

        case .Keyword_EndForeach {
            array.pop(&instruction_targets);
        }
    }

    return .{ None = .{} };
}

#local
parse_expression :: (use p: &TemplateParser) -> (&TNode, ParseError) {
    retval: &TNode = null;
    err := ParseError.{ None = .{} };

    switch tkn := p.l->consume(); tkn.type {
        case .Keyword_Block {
            name, err := parse_string(p);
            if err.tag != .None do return null, err;

            retval = make_node(t, .{
                ExprBlock = .{ block_name = name }
            });
        }

        case .Keyword_Partial {
            name, err := parse_string(p);
            if err.tag != .None do return null, err;

            args: [..] &TNode;
            array.init(&args, 1, allocator=as_allocator(&t.node_storage));

            while (p.l->peek()).type != .Expression_End {
                expr, err := parse_expression(p);
                if err.tag != .None do return null, err;

                args << expr;
            }

            partial_expr := make_node(t, .{
                ExprPartial = .{ name, args }
            });

            retval = partial_expr;
        }

        case .Variable {
            name := tkn.text |> string.alloc_copy(as_allocator(&t.node_storage));

            var_expr := make_node(t, .{
                ExprVar = .{ var_name = name }
            });

            retval = var_expr;
        }

        case .Int_Literal {
            value: i32 = ~~ conv.str_to_i64(tkn.text);

            int_expr := make_node(t, .{
                ExprInt = .{ val = value }
            });

            retval = int_expr;
        }

        case #default {
            err = .{ Unexpected_Token = tkn };
        }
    }

    while true do switch tkn := p.l->peek(); tkn.type {
        case .Dot {
            p.l->consume();

            if tkn := p.l->peek(); tkn.type != .Symbol {
                err = .{ Unexpected_Token = tkn };
                break break;
            }

            sym_tkn := p.l->consume();

            select_expr := make_node(t, .{
                ExprSelector = .{
                    var = retval,
                    field = sym_tkn.text |> string.alloc_copy(as_allocator(&t.node_storage)),
                }
            });

            retval = select_expr;
        }

        case .Open_Bracket {
            p.l->consume();

            expr, err~ := parse_expression(p);
            if err.tag != .None do break break;

            subscript_expr := make_node(t, .{
                ExprSubscript = .{ var = retval, sub = expr }
            });

            retval = subscript_expr;

            if tkn := p.l->peek(); tkn.type != .Close_Bracket {
                err = .{ Unexpected_Token = .{} };
                break break;
            }

            p.l->consume();
        }

        case #default do break break;
    }

    return retval, err;
}

#local
parse_string :: (use p: &TemplateParser) -> (str, ParseError) {
    str_tkn := p.l->consume();
    if str_tkn.type != .String_Literal {
        return "", .{ Unexpected_Token = str_tkn };
    }

    value := str_tkn.text |> string.alloc_copy(as_allocator(&t.node_storage));

    return value, .{ None = .{} };
}

#local
expect_token :: #match #local {}

#overload
expect_token :: macro (p: &TemplateParser, type: TemplateToken.Type, out: Code) {
    if (p.l->peek()).type != type {
        return ParseError.{ Expected_Token = type };
    }

    (#unquote out) = p.l->consume();
}

#overload
expect_token :: macro (p: &TemplateParser, type: TemplateToken.Type) {
    if (p.l->peek()).type != type {
        return ParseError.{ Expected_Token = type };
    }

    p.l->consume();
}


#package
make_node :: macro (t: &Template, v: TNode) -> &TNode {
    r := new(TNode, allocator=as_allocator(&t.node_storage));
    *r = v;
    return r;
}

#package
union_as_ptr :: macro (u: & $U, variant: U.tag_enum) => {
    switch u {
        case variant => &v do return v;
    }

    return null;
}